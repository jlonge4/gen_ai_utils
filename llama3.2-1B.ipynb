{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/jldevtech/myenv/lib/python3.12/site-packages (4.45.0)\n",
      "Requirement already satisfied: huggingface_hub in /home/jldevtech/myenv/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: torch in /home/jldevtech/myenv/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: accelerate in /home/jldevtech/myenv/lib/python3.12/site-packages (0.34.2)\n",
      "Requirement already satisfied: filelock in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jldevtech/myenv/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jldevtech/myenv/lib/python3.12/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jldevtech/myenv/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/jldevtech/myenv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/jldevtech/myenv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/jldevtech/myenv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/jldevtech/myenv/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: psutil in /home/jldevtech/myenv/lib/python3.12/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jldevtech/myenv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jldevtech/myenv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jldevtech/myenv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jldevtech/myenv/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jldevtech/myenv/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jldevtech/myenv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U transformers huggingface_hub torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /home/jldevtech/myenv/lib/python3.12/site-packages (0.42.0)\n",
      "Requirement already satisfied: scipy in /home/jldevtech/myenv/lib/python3.12/site-packages (from bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /home/jldevtech/myenv/lib/python3.12/site-packages (from scipy->bitsandbytes) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[?7l\u001b[0m\u001b[31m\u001b[1m            .-/+oossssoo+/-.\n",
      "        `:+ssssssssssssssssss+:`\n",
      "      -+ssssssssssssssssssyyssss+-\n",
      "    .ossssssssssssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNy\u001b[0m\u001b[31m\u001b[1msssso.\n",
      "   /sssssssssss\u001b[37m\u001b[0m\u001b[1mhdmmNNmmyNMMMMh\u001b[0m\u001b[31m\u001b[1mssssss/\n",
      "  +sssssssss\u001b[37m\u001b[0m\u001b[1mhm\u001b[0m\u001b[31m\u001b[1myd\u001b[37m\u001b[0m\u001b[1mMMMMMMMNddddy\u001b[0m\u001b[31m\u001b[1mssssssss+\n",
      " /ssssssss\u001b[37m\u001b[0m\u001b[1mhNMMM\u001b[0m\u001b[31m\u001b[1myh\u001b[37m\u001b[0m\u001b[1mhyyyyhmNMMMNh\u001b[0m\u001b[31m\u001b[1mssssssss/\n",
      ".ssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNh\u001b[0m\u001b[31m\u001b[1mssssssssss\u001b[37m\u001b[0m\u001b[1mhNMMMd\u001b[0m\u001b[31m\u001b[1mssssssss.\n",
      "+ssss\u001b[37m\u001b[0m\u001b[1mhhhyNMMNy\u001b[0m\u001b[31m\u001b[1mssssssssssss\u001b[37m\u001b[0m\u001b[1myNMMMy\u001b[0m\u001b[31m\u001b[1msssssss+\n",
      "oss\u001b[37m\u001b[0m\u001b[1myNMMMNyMMh\u001b[0m\u001b[31m\u001b[1mssssssssssssss\u001b[37m\u001b[0m\u001b[1mhmmmh\u001b[0m\u001b[31m\u001b[1mssssssso\n",
      "oss\u001b[37m\u001b[0m\u001b[1myNMMMNyMMh\u001b[0m\u001b[31m\u001b[1msssssssssssssshmmmh\u001b[0m\u001b[31m\u001b[1mssssssso\n",
      "+ssss\u001b[37m\u001b[0m\u001b[1mhhhyNMMNy\u001b[0m\u001b[31m\u001b[1mssssssssssss\u001b[37m\u001b[0m\u001b[1myNMMMy\u001b[0m\u001b[31m\u001b[1msssssss+\n",
      ".ssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNh\u001b[0m\u001b[31m\u001b[1mssssssssss\u001b[37m\u001b[0m\u001b[1mhNMMMd\u001b[0m\u001b[31m\u001b[1mssssssss.\n",
      " /ssssssss\u001b[37m\u001b[0m\u001b[1mhNMMM\u001b[0m\u001b[31m\u001b[1myh\u001b[37m\u001b[0m\u001b[1mhyyyyhdNMMMNh\u001b[0m\u001b[31m\u001b[1mssssssss/\n",
      "  +sssssssss\u001b[37m\u001b[0m\u001b[1mdm\u001b[0m\u001b[31m\u001b[1myd\u001b[37m\u001b[0m\u001b[1mMMMMMMMMddddy\u001b[0m\u001b[31m\u001b[1mssssssss+\n",
      "   /sssssssssss\u001b[37m\u001b[0m\u001b[1mhdmNNNNmyNMMMMh\u001b[0m\u001b[31m\u001b[1mssssss/\n",
      "    .ossssssssssssssssss\u001b[37m\u001b[0m\u001b[1mdMMMNy\u001b[0m\u001b[31m\u001b[1msssso.\n",
      "      -+sssssssssssssssss\u001b[37m\u001b[0m\u001b[1myyy\u001b[0m\u001b[31m\u001b[1mssss+-\n",
      "        `:+ssssssssssssssssss+:`\n",
      "            .-/+oossssoo+/-.\u001b[0m\n",
      "\u001b[20A\u001b[9999999D\u001b[43C\u001b[0m\u001b[1m\u001b[31m\u001b[1mjldevtech\u001b[0m@\u001b[31m\u001b[1mjldevtech-pi\u001b[0m \n",
      "\u001b[43C\u001b[0m----------------------\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mOS\u001b[0m\u001b[0m:\u001b[0m Ubuntu 24.04 LTS aarch64\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mHost\u001b[0m\u001b[0m:\u001b[0m Raspberry Pi 5 Model B Rev 1.0\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mKernel\u001b[0m\u001b[0m:\u001b[0m 6.8.0-1008-raspi\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mUptime\u001b[0m\u001b[0m:\u001b[0m 2 days, 24 mins\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mPackages\u001b[0m\u001b[0m:\u001b[0m 1848 (dpkg), 10 (snap)\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mShell\u001b[0m\u001b[0m:\u001b[0m bash 5.2.21\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mTerminal\u001b[0m\u001b[0m:\u001b[0m node\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mCPU\u001b[0m\u001b[0m:\u001b[0m (4) @ 2.400GHz\u001b[0m \n",
      "\u001b[43C\u001b[0m\u001b[31m\u001b[1mMemory\u001b[0m\u001b[0m:\u001b[0m 1433MiB / 7942MiB\u001b[0m \n",
      "\n",
      "\u001b[43C\u001b[30m\u001b[40m   \u001b[31m\u001b[41m   \u001b[32m\u001b[42m   \u001b[33m\u001b[43m   \u001b[34m\u001b[44m   \u001b[35m\u001b[45m   \u001b[36m\u001b[46m   \u001b[37m\u001b[47m   \u001b[m\n",
      "\u001b[43C\u001b[38;5;8m\u001b[48;5;8m   \u001b[38;5;9m\u001b[48;5;9m   \u001b[38;5;10m\u001b[48;5;10m   \u001b[38;5;11m\u001b[48;5;11m   \u001b[38;5;12m\u001b[48;5;12m   \u001b[38;5;13m\u001b[48;5;13m   \u001b[38;5;14m\u001b[48;5;14m   \u001b[38;5;15m\u001b[48;5;15m   \u001b[m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[?25h\u001b[?7h"
     ]
    }
   ],
   "source": [
    "!neofetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ed05390a264a5ebdb69b502148ac6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:           7.8Gi       1.7Gi       458Mi        17Mi       5.8Gi       6.0Gi\n",
      "Swap:          1.0Gi       768Ki       1.0Gi\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afe9c3b3b9e4d00a7e9da7abcdd5b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80346e91364441bcaf8ef02c121443a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:01<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0bbd597e324cc1b926af869fb4189b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1b1efcf23d4cabbdbf3cf19486409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00dc79da09e481bb88793cc800bf523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pprint\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True,device_map=\"cpu\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\",\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a professional in machine learning who is a master educator.\"},\n",
    "    {\"role\": \"user\", \"content\": \"In regard to clustering. Explain the process of permuting my data 1000 times, running k means and then getting a silhouette score for each to ensure that 2% or less have a silhouettes score greater tha n or equal to 0.65\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jldevtech/myenv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/jldevtech/myenv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'I can guide you through the process of permuting your data, '\n",
      "            'running K-Means clustering, and calculating the silhouette score '\n",
      "            \"for each permutation. Here's a step-by-step explanation:\\n\"\n",
      "            '\\n'\n",
      "            '**Permuting Data**\\n'\n",
      "            '\\n'\n",
      "            'To generate multiple permutations of your data, you can use the '\n",
      "            \"`permute` function in R or Python. Here's an example using R:\\n\"\n",
      "            '```r\\n'\n",
      "            '# Load the data\\n'\n",
      "            'data <- data.frame(x = rnorm(1000, mean = 0, sd = 1),\\n'\n",
      "            '                   y = rnorm(1000, mean = 0, sd = 1))\\n'\n",
      "            '\\n'\n",
      "            '# Permute the data 1000 times\\n'\n",
      "            'set.seed(123)  # For reproducibility\\n'\n",
      "            'permutations <- replicate(1000, permute(data, 1000), simplify = '\n",
      "            'TRUE)\\n'\n",
      "            '```\\n'\n",
      "            'In this example, we generate 1000 permutations of the data using '\n",
      "            'the `permute` function, which returns a list of 1000 data frames. '\n",
      "            'We then use the `replicate` function to run the permutation '\n",
      "            'process 1000 times.\\n'\n",
      "            '\\n'\n",
      "            '**Running K-Means Clustering**\\n'\n",
      "            '\\n'\n",
      "            'To run K-Means clustering, we can use the `kmeans` function in R '\n",
      "            \"or Python. Here's an example using R:\\n\"\n",
      "            '```',\n",
      " 'role': 'assistant'}\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=False,\n",
    ")\n",
    "pprint.pprint(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:           7.8Gi       6.1Gi       1.2Gi       3.8Mi       606Mi       1.6Gi\n",
      "Swap:          1.0Gi       595Mi       428Mi\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
