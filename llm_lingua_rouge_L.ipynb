{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPESI2wy8GabQZX/c1BUHTs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_qoGU0BNajG",
        "outputId": "b508b9f7-6390-4752-91d2-d4d0e7ca8b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tiktoken, accelerate, llmlingua\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 llmlingua-0.1.5 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install llmlingua accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain boto3 rouge-score"
      ],
      "metadata": {
        "id": "ULzk8g-rNuea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "bedrock = boto3.client('bedrock-runtime',\n",
        "                      region_name='us-east-1')"
      ],
      "metadata": {
        "id": "LGdadZoHRJIP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llmlingua import PromptCompressor\n",
        "\n",
        "llm_lingua = PromptCompressor()"
      ],
      "metadata": {
        "id": "013WuMgMNdAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader('https://openai.com/research/overview')"
      ],
      "metadata": {
        "id": "gXt5SMjaOhq3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "DizOEF15O-D6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kffO-7tKO_3J",
        "outputId": "2b58b1a9-4987-40d9-999e-a7a39e6447cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"\\n\\n\\nResearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexGPT-4DALL·E 3APIOverviewData privacyPricingDocsChatGPTOverviewEnterpriseTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer storiesSearch Navigation quick links Log inTry ChatGPTMenu Mobile Navigation CloseSite NavigationResearchOverviewIndexGPT-4DALL·E 3APIOverviewData privacyPricingDocsChatGPTOverviewEnterpriseTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer stories Quick Links Log inTry ChatGPTSearch Submit Pioneering research on the path to AGIWe believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Building safe and beneficial AGI is our mission.Quick linksView research indexLearn about safetySafely aligning powerful AI systems is one of the most important unsolved problems for our mission. Techniques like learning from human feedback are helping us get closer, and we are actively researching new techniques to help us fill the gaps.Josh AchiamResearcher at OpenAIFocus areasWe build our generative models using a technology called deep learning, which leverages large amounts of data to train an AI system to perform a task.TextOur text models are advanced language processing tools that can generate, classify, and summarize text with high levels of coherence and accuracy.Aligning language models to follow instructionsWe’ve trained language models that are much better at following user intentions than GPT-3.Summarizing books with human feedbackWe've trained a model to summarize entire books with human feedback.Language models are few-shot learnersWe trained GPT-3, an autoregressive language model with 175 billion parameters.ImageOur research on generative modeling for images has led to representation models like CLIP, which makes a map between text and images that an AI can read, and DALL-E, a tool for creating vivid images from text descriptions.Hierarchical text-conditional image generation with CLIP latentsWe show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity.DALL·E: Creating images from textWe’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.CLIP: Connecting text and imagesWe’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision.AudioOur research on applying AI to audio processing and audio generation has led to developments in automatic speech recognition and original musical compositions.Introducing WhisperWe’ve trained and are open-sourcing a neural net that approaches human level robustness and accuracy on English speech recognition.JukeboxWe’re introducing Jukebox, a neural net that generates music as raw audio in a variety of genres and artist styles.MuseNetWe’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments.Past highlightsOur current AI research builds upon a wealth of previous projects and advances.View all researchImage GPTJun 17, 2020June 17, 2020Solving Rubik’s Cube with a robot handOct 15, 2019October 15, 2019Emergent tool use from multi-agent interactionSep 17, 2019September 17, 2019Featured rolesWe are constantly seeking talented individuals to join our team. Explore featured roles or view all open roles.View all careersSenior Software Engineer, ChatGPT Model OptimizationSan Francisco, California, United States — Applied AI EngineeringApply nowInsider Risk InvestigatorSan Francisco, California, United States — Corporate SecurityApply nowAccount Director, ChatGPT EnterpriseNew York City, New York, United States — Go To MarketApply nowAccount Director, Platform Strategic AccountsLondon, UK — Go To MarketApply nowAccount Director, Platform ScaleSan Francisco, California, United States — Go To MarketApply nowResearchOverviewIndexGPT-4DALL·E 3APIOverviewData privacyPricingDocsChatGPTOverviewEnterpriseTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI © 2015\\u200a–\\u200a2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top\\n\", metadata={'source': 'https://openai.com/research/overview', 'title': 'Research', 'description': 'We believe our research will eventually lead to artificial general intelligence, a system that can solve human-level problems. Building safe and beneficial AGI is our mission.', 'language': 'en-US'})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"You are a helpful article research assistant\"\n",
        "question = \"Using two sentences, tell me what OpenAI is currently researching based on the article, do not use a preamble\"\n",
        "context = docs[0].page_content"
      ],
      "metadata": {
        "id": "AVRzMInMPE6Y"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = instruction + '\\n\\n' + context + '\\n\\n' + question\n",
        "len(prompt.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOUGPBgaPh64",
        "outputId": "e59f1934-ea1d-4aea-b6f4-0fd1ae63840a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_prompt = llm_lingua.compress_prompt(\n",
        "    context = [context],\n",
        "    instruction = instruction,\n",
        "    question = question,\n",
        "    target_token = 350,\n",
        "    rank_method = 'longllmlingua'\n",
        ")"
      ],
      "metadata": {
        "id": "zjt16LyBPmJW"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(compressed_prompt['compressed_prompt'].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnAMuElQXqa",
        "outputId": "4b73cc25-1da0-44d1-8807-80f4b4f1d731"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pi7WadBQOGO",
        "outputId": "c17939dc-ba0c-4efa-b8d8-2cbf385e33f9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compressed_prompt': 'You are a helpful article research assistant\\n\\n\\n\\nearch\\n\\nCloseSearchmit contentSite NavigationearchviewIndexG-4DALLE 3APIviewDataacyingocsPTviewprisePTetyAboutersRescyCharterSecurity storiesSearch Navigation links inPTMenu Mobile Navigation Close storiesPTSearchmit Pering research theIWe believe will to, system that can solve humanlevel. Building andicial. linksView research index about safetyafelying systems important problems our. Te like are closer are us.Joshiamer OpenAIF areasWe build our a called which train.Textur are advanced language processing generate, text high of.ing to instructionsve are following user intent than.izing withWe a toize entire books with human.Language areersWe,.Imageuring to which makes a images that creating.Hical-P that explicitly representations imageity with in and.We networkptions concepts.:’P whichns language.Audio on to and original.cingper neural that level on.Jre music as and.M generateastur a. researchImagePT00ving a99gent tool from9dore,PT States now now, Platformaleearchview4DALL·E 3APIOverviewData privacyPricingDocsChatGPTOverviewEnterpriseTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI © 2015\\u200a–\\u200a2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top\\n\\n\\nUsing two sentences, tell me what OpenAI is currently researching based on the article, do not use a preamble',\n",
              " 'origin_tokens': 894,\n",
              " 'compressed_tokens': 314,\n",
              " 'ratio': '2.8x',\n",
              " 'saving': ', Saving $0.0 in GPT-4.'}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Bedrock\n",
        "llm = Bedrock(client=bedrock, model_id='anthropic.claude-v2')"
      ],
      "metadata": {
        "id": "IyIkJkC9REus"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "original = llm(prompt)\n",
        "condensed = llm(compressed_prompt['compressed_prompt'])\n",
        "pprint(f\"Original: {original}\")\n",
        "print('#' * 60)\n",
        "pprint(f\"Condensed: {condensed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXD0xegsYAAp",
        "outputId": "d01b4977-d5b9-4c52-8ed8-cd06e52593d7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Original:  Based on the article, OpenAI is currently researching natural '\n",
            " 'language processing and generative models for text, images, and audio. They '\n",
            " 'are developing advanced language models like GPT-3 and image generation '\n",
            " 'models like DALL-E.')\n",
            "############################################################\n",
            "('Condensed:  Based on the article, OpenAI is currently researching advanced '\n",
            " 'language processing to generate high-quality text and images. They are '\n",
            " 'developing systems like GPT-3 and DALL-E that can generate text and images '\n",
            " 'from instructions to better capture user intent.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "rs = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "rs.score(original, condensed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMdu9PUARarh",
        "outputId": "6269bf47-b655-46a1-a450-e1372af72f20"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rougeL': Score(precision=0.5365853658536586, recall=0.6285714285714286, fmeasure=0.5789473684210527)}"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    }
  ]
}