{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQjXst0etdM/iZD3Ttwr7T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlonge4/gen_ai_utils/blob/main/faiss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i_2V5kHrMFO"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain openai faiss-cpu sentence_transformers chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import openai\n",
        "key = 'key'\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=key,\n",
        "    temperature=0,\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "7eHcV6w_rb_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "14LltcEarlzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# initialize sentence transformer model\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "# create sentence embeddings\n"
      ],
      "metadata": {
        "id": "hwzYAiy8h5hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "two_web_links = [\"https://www.databricks.com/\",\"https://help.databricks.com\",\"https://databricks.com/try-databricks\",\"https://help.databricks.com/s/\",\"https://docs.databricks.com\",\"https://kb.databricks.com/\",\"http://docs.databricks.com/getting-started/index.html\",\"http://docs.databricks.com/introduction/index.html\",\"http://docs.databricks.com/getting-started/tutorials/index.html\",\"http://docs.databricks.com/release-notes/index.html\",\"http://docs.databricks.com/ingestion/index.html\",\"http://docs.databricks.com/exploratory-data-analysis/index.html\",\"http://docs.databricks.com/data-preparation/index.html\",\"http://docs.databricks.com/data-sharing/index.html\",\"http://docs.databricks.com/marketplace/index.html\",\"http://docs.databricks.com/workspace-index.html\",\"http://docs.databricks.com/machine-learning/index.html\",\"http://docs.databricks.com/sql/index.html\",\"http://docs.databricks.com/delta/index.html\",\"http://docs.databricks.com/dev-tools/index.html\",\"http://docs.databricks.com/integrations/index.html\",\"http://docs.databricks.com/administration-guide/index.html\",\"http://docs.databricks.com/security/index.html\",\"http://docs.databricks.com/data-governance/index.html\",\"http://docs.databricks.com/lakehouse-architecture/index.html\",\"http://docs.databricks.com/reference/api.html\",\"http://docs.databricks.com/resources/index.html\",\"http://docs.databricks.com/whats-coming.html\",\"http://docs.databricks.com/archive/index.html\",\"http://docs.databricks.com/lakehouse/index.html\",\"http://docs.databricks.com/getting-started/quick-start.html\",\"http://docs.databricks.com/getting-started/etl-quick-start.html\",\"http://docs.databricks.com/getting-started/lakehouse-e2e.html\",\"http://docs.databricks.com/getting-started/free-training.html\",\"http://docs.databricks.com/sql/language-manual/index.html\",\"http://docs.databricks.com/error-messages/index.html\",\"http://www.apache.org/\",\"https://databricks.com/privacy-policy\",\"https://databricks.com/terms-of-use\"]\n",
        "web_links = [\"https://www.pinecone.io/learn/vector-embeddings/\", \"https://www.featureform.com/post/the-definitive-guide-to-embeddings\"]\n",
        "loader = WebBaseLoader(web_links)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "nbdLOf9gfWLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import metadata\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "malCge8zfdIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtguaiwmbKYB",
        "outputId": "ef9f3ed1-68e9-4cec-923e-766216b0233b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for d in all_splits:\n",
        "  docs.append(d.page_content)"
      ],
      "metadata": {
        "id": "oOae0Y_PisZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "dXwMAQU9lq3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b42f2cb6-408f-4e0e-83c2-69b277679298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What are Vector Embeddings | PineconeProductSolutionsPricingResourcesCompanyLog InSign Up FreeLearn | ArticleWhat are Vector EmbeddingsJump to section IntroductionCreating Vector EmbeddingsExample: Image Embedding with a Convolutional Neural NetworkUsing Vector EmbeddingsIntroductionVector embeddings are one of the most fascinating and useful concepts in machine learning. They are central to many NLP, recommendation, and search algorithms. If you’ve ever used things like recommendation engines, voice assistants, language translators, you’ve come across systems that rely on embeddings.ML algorithms, like most software algorithms, need numbers to work with. Sometimes we have a dataset with columns of numeric values or values that can be translated into them (ordinal, categorical, etc). Other times we come across something more abstract like an entire document of text. We create vector embeddings, which are just lists of numbers, for data like this to perform various operations with them.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXFLATL2"
      ],
      "metadata": {
        "id": "ct_s3fgGgLIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "vectorstore = FAISS.from_documents(all_splits, embedding_function)"
      ],
      "metadata": {
        "id": "hdJcEmUwePDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "query = 'What is a vector embedding?, only use context information to answer, if there isnt anything related, reply I dont know.'\n",
        "vectorstore.similarity_search_with_relevance_scores(query)[1][1]\n",
        "\n",
        "# chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n",
        "\n",
        "# chat_history = []\n",
        "# start = time.time()\n",
        "# result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "# end = time.time()\n",
        "# print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXt_oOmoBoA",
        "outputId": "45f7fd11-7732-46cb-8819-38b54a61c1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6022298448717652"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L2 = result['answer']"
      ],
      "metadata": {
        "id": "d9lbBA3-q4Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "9HWYMDypbaxF",
        "outputId": "2434cf28-55da-4812-ea97-6a57f120e56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A vector embedding is a representation of an object or concept as a vector in a multi-dimensional space. It is created by assigning specific values to each dimension of the vector based on the relationship between different objects or concepts. Vector embeddings are commonly used in various applications to capture similarities and relationships between different entities.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXIVFFLAT"
      ],
      "metadata": {
        "id": "nkHbsBV6gOl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings = model.encode(docs)\n",
        "d = sentence_embeddings.shape[1]\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKgg9zvoguM1",
        "outputId": "e3aca8ce-045c-4b01-b471-6ddc21ae3ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "nlist = 16  # how many cells\n",
        "quantizer = faiss.IndexFlatL2(d)\n",
        "index = faiss.IndexIVFFlat(quantizer,d, nlist)"
      ],
      "metadata": {
        "id": "_juf2U_KggCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xq = model.encode([\"What is a vector embedding?\"])"
      ],
      "metadata": {
        "id": "IBcHsP_Uc3Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faiss.normalize_L2(sentence_embeddings)\n",
        "faiss.normalize_L2(xq)"
      ],
      "metadata": {
        "id": "fduKOpaWZT99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.train(sentence_embeddings)\n",
        "index.add(sentence_embeddings)"
      ],
      "metadata": {
        "id": "BOB_BDxvnA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "k = 4\n",
        "D, I = index.search(xq, k)\n",
        "print(D, I)\n",
        "IVF =  I[0][0]\n"
      ],
      "metadata": {
        "id": "Ee9FTPeBn0fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba02c7f3-1ba9-4a83-8ac4-14edf675880f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0349531 1.0921106 1.102596  1.1371037]] [[ 7  1 20  6]]\n",
            "CPU times: user 704 µs, sys: 0 ns, total: 704 µs\n",
            "Wall time: 711 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[I[0][0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "7APNUpm_ZvJW",
        "outputId": "cc4a96f5-9fa0-44f1-d6d8-83feec5e0702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'encoder contain the necessary information for the decoder to produce a result. This architecture is widely used in applications, such as machine translation and caption generation.Check out some applications you can build with vector embeddings and Pinecone.Share via:  Rajat TripathiSoftware EngineerJump to section IntroductionCreating Vector EmbeddingsExample: Image Embedding with a Convolutional Neural NetworkUsing Vector EmbeddingsPRODUCTOverviewDocumentationTrust and SecuritySOLUTIONSSearchGenerative AICustomersRESOURCESLearning CenterCommunityPinecone BlogSupport CenterSystem StatusCOMPANYAboutPartnersCareersNewsroomContactLEGALTermsPrivacyCookies© Pinecone Systems, Inc. | San Francisco, CAPinecone is a registered trademark of Pinecone Systems, Inc.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import time\n",
        "\n",
        "llm = OpenAI(temperature=0.9,openai_api_key=key)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"source\"],\n",
        "    template=\"Given the context ### {source}###?\" + \"What is a vector embedding?\",\n",
        ")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "start = time.time()\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "\n",
        "IVFFLAT = chain.run(docs[IVF])\n",
        "print(IVFFLAT)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjuf-_xPfC6H",
        "outputId": "ce422a0a-5694-47de-88e7-beda48506282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Vector embeddings are mappings of data into a dimensional space that enables machines to reason with it in a meaningful way. They allow machines to find patterns in data that would be difficult for humans to identify or classify. Vector embeddings can be used for tasks such as image recognition, text classification, speech recognition, and natural language processing. With Pinecone, you can use vector embeddings to build machine learning applications that unlock insights from your data. Some examples of applications you can build with vector embeddings and Pinecone include: \n",
            "\n",
            "- Image recognition\n",
            "- Text classification\n",
            "- Speech recognition\n",
            "- Natural language processing\n",
            "- Sentiment analysis\n",
            "- Recommendation systems\n",
            "- Image captioning\n",
            "- Chatbot development\n",
            "3.639477014541626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEXIVFPQ"
      ],
      "metadata": {
        "id": "homQFPeCri3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 4  # number of centroid IDs in final compressed vectors\n",
        "bits = 4 # number of bits in each centroid\n",
        "\n",
        "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
        "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)"
      ],
      "metadata": {
        "id": "HK0UNEjGezcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.train(sentence_embeddings)\n",
        "index.add(sentence_embeddings)\n",
        "index.nprobe = 3  # align to previous IndexIVFFlat nprobe value"
      ],
      "metadata": {
        "id": "g6sE4OU-fGUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "k =4\n",
        "D, I = index.search(xq, k)\n",
        "print(D, I)\n",
        "PQ = I[0][0]"
      ],
      "metadata": {
        "id": "fIZepw4or5Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5255732-fc92-4d72-f2e5-187a6d3aa5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0130075 1.0130075 1.0407193 1.0407193]] [[20 51  7 38]]\n",
            "CPU times: user 1.01 ms, sys: 0 ns, total: 1.01 ms\n",
            "Wall time: 917 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9,openai_api_key=key)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"source\"],\n",
        "    template=\"Given the context ### {source}###?\" + \"What is a vector embedding?\",\n",
        ")\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "start = time.time()\n",
        "\n",
        "# Run the chain only specifying the input variable.\n",
        "result = chain.run(docs[PQ])\n",
        "print(result)\n",
        "IVFPQ = result\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kn6CMA8sO8T",
        "outputId": "8736fb2d-1437-4445-97ee-45049ebce21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Vector embedding is a technique used in natural language processing (NLP) to represent text and images as numerical vectors so they can be used in machine learning models. It maps words, phrases, and sentences to numerical vectors of fixed size that are then used in a variety of neural networks and other machine learning models. These vectors capture the semantic meaning of the words and phrases in the text, allowing the model to understand the context of the text and create more meaningful predictions. Vector embedding techniques have been used to create models for sentiment analysis, document classification, and other NLP tasks.\n",
            "2.924916982650757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "times = {\"INDEXFLATL2\": 3.978,\n",
        " \"INDEXIVFFLAT\": 3.015,\n",
        " \"INDEXIVFPQ\": 1.840}\n",
        "from pprint import pprint\n",
        "pprint(str(times).strip('{').strip(',').strip('}'))\n",
        "answers = times = {\"INDEXFLATL2\": L2,\n",
        " \"INDEXIVFFLAT\": IVFFLAT.strip('\\n'),\n",
        " \"INDEXIVFPQ\": IVFPQ.strip('\\n')}\n",
        "print('\\n')\n",
        "pprint(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "9y9g0lWYsbSb",
        "outputId": "6f72f8e9-a2ee-4f06-e5ca-d4e88208ddea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"'INDEXFLATL2': 3.978, 'INDEXIVFFLAT': 3.015, 'INDEXIVFPQ': 1.84\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-aa388b076afb>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m answers = times = {\"INDEXFLATL2\": L2,\n\u001b[0m\u001b[1;32m      7\u001b[0m  \u001b[0;34m\"INDEXIVFFLAT\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIVFFLAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m  \"INDEXIVFPQ\": IVFPQ.strip('\\n')}\n",
            "\u001b[0;31mNameError\u001b[0m: name 'L2' is not defined"
          ]
        }
      ]
    }
  ]
}