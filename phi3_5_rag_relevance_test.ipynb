{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPqDutxJO+eVZo73XymzS6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlonge4/gen_ai_utils/blob/main/phi3_5_rag_relevance_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets accelerate peft bitsandbytes flash-attn pycm transformers"
      ],
      "metadata": {
        "id": "7Ay3NYzqXi4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3VduA7VXWNm"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "base_model_id = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "groundedai_eval_id = \"grounded-ai/phi3.5-rag-relevance-judge\"\n",
        "\n",
        "if torch.cuda.is_bf16_supported():\n",
        "  compute_dtype = torch.bfloat16\n",
        "  attn_implementation = 'flash_attention_2'\n",
        "# If bfloat16 is not supported, 'compute_dtype' is set to 'torch.float16' and 'attn_implementation' is set to 'sdpa'.\n",
        "else:\n",
        "  compute_dtype = torch.float16\n",
        "  attn_implementation = 'sdpa'\n",
        "\n",
        "config = PeftConfig.from_pretrained(groundedai_eval_id)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(base_model_id, attn_implementation=attn_implementation,torch_dtype=compute_dtype)\n",
        "model_peft = PeftModel.from_pretrained(base_model, groundedai_eval_id, config=config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "merged_model = model_peft.merge_and_unload()\n",
        "merged_model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_func(query, text):\n",
        "    input = f\"\"\"\n",
        "          You are comparing a reference text to a question and trying to determine if the reference text\n",
        "      contains information relevant to answering the question. Here is the data:\n",
        "          [BEGIN DATA]\n",
        "          ************\n",
        "          [Question]: {query}\n",
        "          ************\n",
        "          [Reference text]: {text}\n",
        "          ************\n",
        "          [END DATA]\n",
        "      Compare the Question above to the Reference text. You must determine whether the Reference text\n",
        "      contains information that can answer the Question. Please focus on whether the very specific\n",
        "      question can be answered by the information in the Reference text.\n",
        "      Your response must be single word, either \"relevant\" or \"unrelated\",\n",
        "      and should not contain any text or characters aside from that word.\n",
        "      \"unrelated\" means that the reference text does not contain an answer to the Question.\n",
        "      \"relevant\" means the reference text contains an answer to the Question.\n",
        "      Based on the information provided, is the provided reference relevant to the question? Respond with only \"relevant\" or \"unrelated\"\n",
        "  \"\"\"\n",
        "    return input"
      ],
      "metadata": {
        "id": "jTEuD6GGXZA3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "def run_merged_model(query, text):\n",
        "  input = format_func(query, text)\n",
        "  messages = [\n",
        "      {\"role\": \"user\", \"content\": input}\n",
        "  ]\n",
        "\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=merged_model,\n",
        "      tokenizer=tokenizer,\n",
        "      device='cuda'\n",
        "  )\n",
        "\n",
        "  generation_args = {\n",
        "      \"max_new_tokens\": 2,\n",
        "      \"return_full_text\": False,\n",
        "      \"temperature\": 0.01,\n",
        "      \"do_sample\": True,\n",
        "  }\n",
        "\n",
        "  output = pipe(messages, **generation_args)\n",
        "  torch.cuda.empty_cache()\n",
        "  return output[0]['generated_text'].strip().lower()"
      ],
      "metadata": {
        "id": "BOzz1rT5XdX8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What are the health benefits of drinking green tea?\"\n",
        "# Retrieved Text 1 (Related):\n",
        "rt_1 = '''\n",
        "Green tea is rich in polyphenols, particularly catechins, which are powerful antioxidants. Regular consumption of green tea has been associated with various health benefits, including improved brain function,\n",
        " fat loss, protection against cancer, and a lower risk of heart disease. Some studies suggest that the compounds in green tea can boost metabolic rate and increase fat burning. Additionally, the L-theanine in\n",
        "  green tea may have a calming effect on the mind.\n",
        "'''\n",
        "# Retrieved Text 2 (Unrelated):\n",
        "rt_2 = '''The Great Barrier Reef is the world's largest coral reef system, stretching over 2,300 kilometers off the coast of Australia. It comprises over 2,900 individual reefs and 900 islands. The reef is home\n",
        " to an incredibly diverse ecosystem, including over 1,500 species of fish, 400 types of hard coral, and numerous other marine species. However, climate change and ocean acidification pose significant threats to the\n",
        "  reef's health and survival.'''\n",
        "# Retrieved Text 3 (Unrelated):\n",
        "rt_3 = '''The Industrial Revolution, which began in Britain in the late 18th century, marked a major turning point in human history. It saw the transition from hand production methods to machines, new chemical manufacturing\n",
        " and iron production processes, improved efficiency of water power, the increasing use of steam power, and the development of machine tools. This period of rapid industrial growth transformed economic and social conditions,\n",
        "  leading to urbanization and significant technological innovations.'''\n",
        "# hard case (unrelated)\n",
        "rt_4 = '''Green tea production is a meticulous process that begins with the careful selection of tea leaves. The leaves are typically harvested from Camellia sinensis plants, with the best quality teas using only the bud and\n",
        "first two leaves. After harvesting, the leaves undergo minimal oxidation through a process of withering and steaming or pan-firing. This halts the oxidation process and preserves the tea's natural green color and delicate\n",
        " flavor profile. The leaves are then rolled and dried to create the final product. Different regions, particularly in China and Japan, have developed unique processing methods that result in various green tea varieties,\n",
        " each with its distinct characteristics and flavor notes.'''"
      ],
      "metadata": {
        "id": "_Fs5T5G5YB8T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#relevant\n",
        "run_merged_model(q, rt_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XsJRkqNgYjZM",
        "outputId": "3fe712ef-840e-485c-f069-115d304a7b57"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'relevant'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unrelated\n",
        "run_merged_model(q, rt_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fpid0gi8YnBU",
        "outputId": "e44e8da2-88f9-4b8b-f8cb-ff42c4efc2d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unrelated'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_merged_model(q, rt_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AtCX4LYHYrFj",
        "outputId": "f035200c-58e1-42e6-8bd4-28ae1aa85b41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unrelated'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hard case\n",
        "run_merged_model(q, rt_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iMOli3fpYtFi",
        "outputId": "b8c2eb7d-d07e-4d07-e9d7-5d7b55ade445"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unrelated'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}